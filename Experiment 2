{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dbbd27b-8b5f-4647-b533-c2c214d09dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading Data (Iris Dataset) ---\n",
      "Iris dataset loaded successfully.\n",
      "\n",
      "--- 2. Dataset Details and Initial Inspection ---\n",
      "\n",
      "Shape (Rows, Columns): (150, 5)\n",
      "\n",
      "First 5 Rows:\n",
      "   sepal_length  sepal_width  petal_length  petal_width      species\n",
      "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
      "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
      "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
      "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
      "4           5.0          3.6           1.4          0.2  Iris-setosa\n",
      "\n",
      "Data Types and Non-Null Counts (df.info()):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n",
      "\n",
      "Missing Values (Count and Percentage):\n",
      "No missing values detected.\n",
      "\n",
      "Descriptive Statistics (Numerical Columns):\n",
      "              count      mean       std  min  25%   50%  75%  max\n",
      "sepal_length  150.0  5.843333  0.828066  4.3  5.1  5.80  6.4  7.9\n",
      "sepal_width   150.0  3.054000  0.433594  2.0  2.8  3.00  3.3  4.4\n",
      "petal_length  150.0  3.758667  1.764420  1.0  1.6  4.35  5.1  6.9\n",
      "petal_width   150.0  1.198667  0.763161  0.1  0.3  1.30  1.8  2.5\n",
      "\n",
      "Mode for Key Categorical Columns ('species'):\n",
      "species    Iris-setosa\n",
      "\n",
      "--- 3. Outlier Detection and Treatment for 'petal_width' (IQR Method) ---\n",
      "Q1: 0.30, Q3: 1.80, IQR: 1.50\n",
      "Lower Bound: -1.95, Upper Bound: 4.05\n",
      "Number of Outliers detected in 'petal_width': 0\n",
      "Number of Outliers after capping: 0\n",
      "\n",
      "Descriptive Stats for 'petal_width' after treatment:\n",
      "count    150.000000\n",
      "mean       1.198667\n",
      "std        0.763161\n",
      "min        0.100000\n",
      "25%        0.300000\n",
      "50%        1.300000\n",
      "75%        1.800000\n",
      "max        2.500000\n",
      "\n",
      "--- 4. Final Dataset Summary ---\n",
      "Final DataFrame Shape (Full): (150, 5)\n",
      "\n",
      "--- 5. Saving Cleaned Data Subset (First 20 Entries) ---\n",
      "Subset DataFrame Shape: (20, 5)\n",
      "Cleaned dataset subset (first 20 rows) successfully saved to: 'iris_cleaned.csv'\n",
      "EDA Complete. Data is now ready for feature engineering and modeling.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Dataset Loading and Initial Overview ---\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads the Iris dataset from the UCI repository.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The loaded DataFrame.\n",
    "    \"\"\"\n",
    "    print(\"--- 1. Loading Data (Iris Dataset) ---\")\n",
    "    \n",
    "    # UCI Iris Dataset URL (standard library dataset)\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "    column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(url, header=None, names=column_names)\n",
    "        print(\"Iris dataset loaded successfully.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "def show_dataset_details(df):\n",
    "    \"\"\"\n",
    "    Displays the initial details of the dataset, including shape, first rows,\n",
    "    data types, missing values summary, and descriptive statistics.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to analyze.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- 2. Dataset Details and Initial Inspection ---\")\n",
    "    \n",
    "    # Rows and Columns\n",
    "    print(f\"\\nShape (Rows, Columns): {df.shape}\")\n",
    "\n",
    "    # First 5 Rows\n",
    "    print(\"\\nFirst 5 Rows:\")\n",
    "    print(df.head())\n",
    "\n",
    "    # Column/Data Types and Non-Null Counts\n",
    "    print(\"\\nData Types and Non-Null Counts (df.info()):\")\n",
    "    df.info()\n",
    "\n",
    "    # Missing Values\n",
    "    print(\"\\nMissing Values (Count and Percentage):\")\n",
    "    missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "    total_rows = len(df)\n",
    "    missing_percent = (missing_data[missing_data > 0] / total_rows) * 100\n",
    "    missing_info = pd.concat([missing_data, missing_percent.round(2)], axis=1, keys=['Missing Count', 'Missing %'])\n",
    "    # Since Iris is clean, this usually won't print anything, but we keep the logic\n",
    "    if not missing_info[missing_info['Missing Count'] > 0].empty:\n",
    "        print(missing_info[missing_info['Missing Count'] > 0])\n",
    "    else:\n",
    "        print(\"No missing values detected.\")\n",
    "    \n",
    "    # Descriptive Statistics\n",
    "    print(\"\\nDescriptive Statistics (Numerical Columns):\")\n",
    "    print(df.describe().T)\n",
    "    \n",
    "    # Descriptive Statistics (Categorical Columns - Mode)\n",
    "    print(\"\\nMode for Key Categorical Columns ('species'):\")\n",
    "    categorical_modes = df[['species']].mode().iloc[0]\n",
    "    print(categorical_modes.to_string())\n",
    "\n",
    "\n",
    "# --- 3. Outlier Detection and Treatment (IQR Method) ---\n",
    "# Note: Missing Value Handling is skipped as Iris is a clean dataset.\n",
    "\n",
    "def detect_and_treat_outliers(df, column='petal_width'):\n",
    "    \"\"\"\n",
    "    Detects and treats outliers in a specified numerical column using the IQR method.\n",
    "    Outliers are identified and capped at the fence boundaries.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame.\n",
    "        column (str): The name of the column to check for outliers.\n",
    "        (Using 'petal_width' for Iris dataset analysis)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with outliers treated (capped).\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 3. Outlier Detection and Treatment for '{column}' (IQR Method) ---\")\n",
    "\n",
    "    # Calculate IQR\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Define bounds\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Detect outliers\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    \n",
    "    print(f\"Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "    print(f\"Lower Bound: {lower_bound:.2f}, Upper Bound: {upper_bound:.2f}\")\n",
    "    print(f\"Number of Outliers detected in '{column}': {len(outliers)}\")\n",
    "\n",
    "    # Treat (Cap) outliers\n",
    "    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])\n",
    "    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])\n",
    "    \n",
    "    # Verify treatment\n",
    "    outliers_after = df[(df[column] < lower_bound) | (df[column] > upper_bound)]\n",
    "    print(f\"Number of Outliers after capping: {len(outliers_after)}\")\n",
    "    print(f\"\\nDescriptive Stats for '{column}' after treatment:\")\n",
    "    print(df[column].describe().to_string())\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 1. Load Data\n",
    "    iris_df = load_data()\n",
    "\n",
    "    if iris_df is not None:\n",
    "        # 2. Show Dataset Details\n",
    "        show_dataset_details(iris_df.copy()) # Use a copy for initial inspection\n",
    "\n",
    "        # 3. Outlier Detection and Treatment\n",
    "        # Note: Iris dataset is typically clean, so we go directly to outlier check\n",
    "        iris_df_final = detect_and_treat_outliers(iris_df, column='petal_width')\n",
    "        \n",
    "        # 4. Final Dataset Summary and Saving\n",
    "        print(\"\\n--- 4. Final Dataset Summary ---\")\n",
    "        print(f\"Final DataFrame Shape (Full): {iris_df_final.shape}\")\n",
    "\n",
    "        # Limit to the first 20 entries as requested\n",
    "        iris_df_subset = iris_df_final.head(20)\n",
    "\n",
    "        # Save the subset cleaned DataFrame to a new CSV file\n",
    "        output_filepath = 'iris_cleaned.csv'\n",
    "        iris_df_subset.to_csv(output_filepath, index=False)\n",
    "        print(f\"\\n--- 5. Saving Cleaned Data Subset (First 20 Entries) ---\")\n",
    "        print(f\"Subset DataFrame Shape: {iris_df_subset.shape}\")\n",
    "        print(f\"Cleaned dataset subset (first 20 rows) successfully saved to: '{output_filepath}'\")\n",
    "        \n",
    "        print(\"EDA Complete. Data is now ready for feature engineering and modeling.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04308aa-9f12-4ead-8d13-cb37d5b4d5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
